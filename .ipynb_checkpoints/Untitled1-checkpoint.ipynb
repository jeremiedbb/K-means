{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from numba import jit, njit, prange, float32\n",
    "import numpy as np\n",
    "from joblib import Memory\n",
    "from sklearn.cluster.k_means_ import _k_init\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.utils import check_random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Memory(location='/tmp/joblib')\n",
    "make_blobs = m.cache(make_blobs)\n",
    "_k_init = m.cache(_k_init)\n",
    "n_clusters = 1000\n",
    "rng = check_random_state(42)\n",
    "kmeanspp_size = int(1e4)\n",
    "\n",
    "data, true_labels = make_blobs(n_samples=int(1e5), centers=100,\n",
    "                               n_features=100, cluster_std=30,\n",
    "                               random_state=rng)\n",
    "data = data.astype(np.float32)\n",
    "data_squared_norms = np.sum(data[:kmeanspp_size] * data[:kmeanspp_size],\n",
    "                            axis=1)\n",
    "centroids = _k_init(data[:kmeanspp_size], n_clusters,\n",
    "                    data_squared_norms, rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit('void(f4[:, ::1], f4[:, ::1], f4[:, ::1], u4[::1])',\n",
    "      locals={'best_dist': float32, 'dist': float32},\n",
    "      fastmath=True,\n",
    "#       parallel=True,\n",
    ")\n",
    "def kmeans_kernel(data, centroids, centroids_sum, centroids_pop):\n",
    "    n_samples, n_features = data.shape\n",
    "    n_centroids = centroids.shape[0]\n",
    "    for i in range(n_samples):\n",
    "        best_dist = 1e7\n",
    "        best_j = 0\n",
    "        for j in range(n_centroids):\n",
    "            dist = 0.\n",
    "            for k in range(n_features):\n",
    "                dist += (data[i, k] - centroids[j, k]) ** 2\n",
    "            if dist < best_dist:\n",
    "                best_dist = dist\n",
    "                best_j = j\n",
    "        for k in range(data.shape[1]):\n",
    "            centroids_sum[best_j, k] += data[i, k]\n",
    "        centroids_pop[best_j] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chunk = data[:1000]\n",
    "centroids_sum = np.zeros_like(centroids)\n",
    "centroids_pop = np.zeros(centroids.shape[0], dtype=np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.5 ms ± 587 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "kmeans_kernel(data_chunk, centroids, centroids_sum, centroids_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CC\"] = 'gcc-8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%cython -c=-Ofast -c=-mavx2 -c=-fprefetch-loop-arrays -f\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "import array\n",
    "from cpython cimport array\n",
    "from libc.string cimport memcpy\n",
    "\n",
    "ctypedef fused floating_t:\n",
    "    np.float32_t\n",
    "    np.float64_t\n",
    "\n",
    "@cython.cdivision(True)  \n",
    "@cython.initializedcheck(False)\n",
    "@cython.nonecheck(False)\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "cpdef void kmeans_chunk_np(np.ndarray[float, ndim=2] X_chunk,\n",
    "                           np.ndarray[float, ndim=2] C,\n",
    "                           np.ndarray[float, ndim=2] sums,\n",
    "                           np.ndarray[int, ndim=1] pops):\n",
    "    cdef:\n",
    "        int n_samples_chunk = X_chunk.shape[0],\n",
    "        int n_clusters = C.shape[0],\n",
    "        int n_features = C.shape[1]\n",
    "        \n",
    "        float x = 0.0\n",
    "        float sq_dist = 0.0\n",
    "        float max_sq_dist = -1.0\n",
    "        int best_cluster = -1\n",
    "\n",
    "        int si, ci, fi = 0\n",
    "\n",
    "    # pairwise dist argmin min \n",
    "    for si in xrange(n_samples_chunk):\n",
    "        max_sq_dist = -10000000\n",
    "        best_cluster = -1\n",
    "        for ci in xrange(n_clusters):\n",
    "            sq_dist = 0.0\n",
    "            for fi in xrange(n_features):\n",
    "                x = X_chunk[si, fi] - C[ci, fi]\n",
    "                sq_dist += x * x\n",
    "            if sq_dist > max_sq_dist:\n",
    "                max_sq_dist = sq_dist\n",
    "                best_cluster = ci\n",
    "\n",
    "        #labels[s_idx] = best_cluster            #update labels\n",
    "        pops[best_cluster] += 1                 #update pops\n",
    "        for fi in xrange(n_features):        #update sums\n",
    "            sums[best_cluster, fi] += X_chunk[si, fi]    \n",
    "    \n",
    "@cython.cdivision(True)  \n",
    "@cython.initializedcheck(False)\n",
    "@cython.nonecheck(False)\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "cdef void kmeans_chunk_(np.float32_t *X_chunk,\n",
    "                        np.float32_t *C,\n",
    "                        np.float32_t *sums,\n",
    "                        np.int32_t *pops,\n",
    "                        Py_ssize_t n_samples_chunk,\n",
    "                        Py_ssize_t n_clusters,\n",
    "                        Py_ssize_t n_features) nogil:\n",
    "    cdef:\n",
    "        np.float32_t x = 0.0\n",
    "        np.float32_t sq_dist = 0.0\n",
    "        np.float32_t max_sq_dist = -1.0\n",
    "        np.int32_t best_cluster = -1\n",
    "\n",
    "        Py_ssize_t si, ci, fi = 0\n",
    "        \n",
    "        np.float32_t *C_start = C\n",
    "        np.float32_t *X_start = X_chunk\n",
    "        \n",
    "\n",
    "    # pairwise dist argmin min \n",
    "    X_start = X_chunk\n",
    "    for si in xrange(n_samples_chunk):\n",
    "        max_sq_dist = -10000000\n",
    "        best_cluster = -1\n",
    "        C_start = C\n",
    "        for ci in xrange(n_clusters):\n",
    "            sq_dist = 0.0\n",
    "            for fi in xrange(n_features):\n",
    "                x = (X_start + fi)[0] - (C_start + fi)[0]\n",
    "                sq_dist += x * x\n",
    "            C_start += n_features\n",
    "            if sq_dist > max_sq_dist:\n",
    "                max_sq_dist = sq_dist\n",
    "                best_cluster = ci\n",
    "        X_start += n_features\n",
    "\n",
    "        #labels[s_idx] = best_cluster            #update labels\n",
    "        pops[best_cluster] += 1                 #update pops\n",
    "        for fi in xrange(n_features):        #update sums\n",
    "            (sums + best_cluster * n_features + fi)[0] += (X_chunk + si * n_features + fi)[0]\n",
    "\n",
    "@cython.cdivision(True)  \n",
    "@cython.initializedcheck(False)\n",
    "@cython.nonecheck(False)\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "cpdef kmeans_chunk_py(np.float32_t[:, ::1] X_chunk,\n",
    "                      np.float32_t[:, ::1] C,\n",
    "                      np.float32_t[:, ::1] sums,\n",
    "                      np.int32_t[::1] pops):\n",
    "    n_samples_chunk, n_features,_,_,_,_,_,_ = X_chunk.shape\n",
    "    n_clusters = C.shape[0]\n",
    "    kmeans_chunk_(&X_chunk[0,0], &C[0,0], &sums[0,0], &pops[0], n_samples_chunk, n_clusters, n_features)\n",
    "    \n",
    "    \n",
    "@cython.cdivision(True)  \n",
    "@cython.initializedcheck(False)\n",
    "@cython.nonecheck(False)\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "cdef void kmeans_chunk_a(np.float32_t *X_chunk,\n",
    "                         np.float32_t *C,\n",
    "                         np.float32_t *sums,\n",
    "                         int *pops,\n",
    "                         Py_ssize_t n_samples_chunk,\n",
    "                         Py_ssize_t n_clusters,\n",
    "                         Py_ssize_t n_features) nogil:\n",
    "    cdef:\n",
    "        np.float32_t x = 0.0\n",
    "        np.float32_t sq_dist = 0.0\n",
    "        np.float32_t max_sq_dist = -1.0\n",
    "        np.int32_t best_cluster = -1\n",
    "\n",
    "        Py_ssize_t si, ci, fi = 0\n",
    "        \n",
    "        np.float32_t *C_start = C\n",
    "        np.float32_t *X_start = X_chunk\n",
    "        \n",
    "\n",
    "    # pairwise dist argmin min \n",
    "    X_start = X_chunk\n",
    "    for si in xrange(n_samples_chunk):\n",
    "        max_sq_dist = -10000000\n",
    "        best_cluster = -1\n",
    "        C_start = C\n",
    "        for ci in xrange(n_clusters):\n",
    "            sq_dist = 0.0\n",
    "            for fi in xrange(n_features):\n",
    "                x = (X_start + fi)[0] - (C_start + fi)[0]\n",
    "                sq_dist += x * x\n",
    "            C_start += n_features\n",
    "            if sq_dist > max_sq_dist:\n",
    "                max_sq_dist = sq_dist\n",
    "                best_cluster = ci\n",
    "        X_start += n_features\n",
    "\n",
    "        #labels[s_idx] = best_cluster            #update labels\n",
    "        pops[best_cluster] += 1                 #update pops\n",
    "        for fi in xrange(n_features):        #update sums\n",
    "            (sums + best_cluster * n_features + fi)[0] += (X_chunk + si * n_features + fi)[0]\n",
    "            \n",
    "@cython.cdivision(True)  \n",
    "@cython.initializedcheck(False)\n",
    "@cython.nonecheck(False)\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "cpdef kmeans_chunk_py_a(np.float32_t[::1] X_chunk,\n",
    "                        np.float32_t[::1] C,\n",
    "                        np.float32_t[::1] sums,\n",
    "                        np.int32_t[::1] pops):\n",
    "    cdef INT_ARRAY = array.array('i')\n",
    "    cdef FLOAT_ARRAY = array.array('f')\n",
    "    \n",
    "    cdef:\n",
    "        Py_ssize_t n_samples_chunk = X_chunk.shape[0] / 100\n",
    "        Py_ssize_t n_features = 100\n",
    "        Py_ssize_t n_clusters = C.shape[0] / 100\n",
    "        \n",
    "        array.array X_chunk_a = array.clone(FLOAT_ARRAY, n_samples_chunk * n_features, False) \n",
    "        array.array C_a = array.clone(FLOAT_ARRAY, n_clusters * n_features, False) \n",
    "        array.array sums_a = array.clone(FLOAT_ARRAY, n_clusters * n_features, True) \n",
    "        array.array pops_a = array.clone(INT_ARRAY, n_clusters, True) \n",
    "        \n",
    "        float *xptr = X_chunk_a.data.as_floats\n",
    "        float *cptr = C_a.data.as_floats\n",
    "        float *sptr = sums_a.data.as_floats\n",
    "        int *pptr = pops_a.data.as_ints\n",
    "        \n",
    "        float x = 0.0\n",
    "        float sq_dist = 0.0\n",
    "        float max_sq_dist = -1.0\n",
    "        int best_cluster = -1\n",
    "\n",
    "        Py_ssize_t si, ci, fi = 0\n",
    "        \n",
    "        float *C_start = cptr\n",
    "        float *X_start = xptr\n",
    "        \n",
    "    memcpy(xptr, &X_chunk[0], n_samples_chunk * n_features * sizeof(int)) \n",
    "    memcpy(cptr, &C[0], n_samples_chunk * n_features * sizeof(int)) \n",
    "    \n",
    "    X_start = xptr\n",
    "    for si in xrange(n_samples_chunk):\n",
    "        max_sq_dist = -10000000\n",
    "        best_cluster = -1\n",
    "        C_start = cptr\n",
    "        for ci in xrange(n_clusters):\n",
    "            sq_dist = 0.0\n",
    "            for fi in xrange(n_features):\n",
    "                x = (X_start + fi)[0] - (C_start + fi)[0]\n",
    "                sq_dist += x * x\n",
    "            C_start += n_features\n",
    "            if sq_dist > max_sq_dist:\n",
    "                max_sq_dist = sq_dist\n",
    "                best_cluster = ci\n",
    "        X_start += n_features\n",
    "\n",
    "        #labels[s_idx] = best_cluster            #update labels\n",
    "        pptr[best_cluster] += 1                  #update pops\n",
    "        for fi in xrange(n_features):            #update sums\n",
    "            (sptr + best_cluster * n_features + fi)[0] += (xptr + si * n_features + fi)[0]\n",
    "            \n",
    "\n",
    "\n",
    "@cython.cdivision(True)  \n",
    "@cython.initializedcheck(False)\n",
    "@cython.nonecheck(False)\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "cpdef void kmeans_chunk_mv(float[::1] X_chunk,\n",
    "                           float[::1] C,\n",
    "                           float[::1] sums,\n",
    "                           float[::1] pops,\n",
    "                           Py_ssize_t n_samples_chunk,\n",
    "                           Py_ssize_t n_clusters,\n",
    "                           Py_ssize_t n_features):\n",
    "    cdef:\n",
    "        float x = 0.0\n",
    "        float sq_dist = 0.0\n",
    "        float max_sq_dist = -1.0\n",
    "        Py_ssize_t best_cluster = -1\n",
    "\n",
    "        Py_ssize_t si, ci, fi, s, c = 0\n",
    "\n",
    "    # pairwise dist argmin min \n",
    "    for si in xrange(n_samples_chunk):\n",
    "        max_sq_dist = -10000000\n",
    "        best_cluster = -1\n",
    "        for ci in xrange(n_clusters):\n",
    "            sq_dist = 0.0\n",
    "            for fi in xrange(n_features):\n",
    "                x = X_chunk[si, fi] - C[ci, fi]\n",
    "                sq_dist += x * x\n",
    "            if sq_dist > max_sq_dist:\n",
    "                max_sq_dist = sq_dist\n",
    "                best_cluster = ci\n",
    "\n",
    "        #labels[s_idx] = best_cluster            #update labels\n",
    "        pops[best_cluster] += 1                 #update pops\n",
    "        for fi in xrange(n_features):        #update sums\n",
    "            sums[best_cluster, fi] += X_chunk[si, fi]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chunk = data[:1000].copy()\n",
    "centroids_sum = np.zeros_like(centroids)\n",
    "centroids_snorms = (centroids**2).sum(axis=1)\n",
    "centroids_pop = np.zeros(centroids.shape[0], dtype='int32')\n",
    "labels = np.empty(100000, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 ms ± 186 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "kmeans_chunk_np(data_chunk, centroids, centroids_sum, centroids_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 ms ± 799 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data_chunk = data[:1000]\n",
    "centroids_sum = np.zeros_like(centroids)\n",
    "centroids_pop = np.zeros(centroids.shape[0], dtype='int32')\n",
    "kmeans_chunk_py(data_chunk, centroids, centroids_sum, centroids_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from libc.string cimport memset\n",
    "#memset(a.data.as_voidptr, 0, len(a) * sizeof(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.3 ms ± 56.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data_chunk = data[:1000]\n",
    "centroids_sum = np.zeros_like(centroids)\n",
    "centroids_pop = np.zeros(centroids.shape[0], dtype='int32')\n",
    "kmeans_chunk_py_a(data_chunk.reshape(1000*100), centroids.reshape(1000*100), centroids_sum.reshape(1000*100), centroids_pop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
